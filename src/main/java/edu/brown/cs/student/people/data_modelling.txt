1. The dataset you created was not bias-free. What are some assumptions that
the developers of Mockaroo made about the types you explored? Who might be left out of the dataset?
Consider the falsehoods you explored earlier.

The Mockaroo website generated a CSV with six columns - first name, last name, birth date, gender, email,
and street address. Its ability to make However, there are a few assumptions it had also made in the structure
of the sample data files. First, its first and last names all assume that the names are on an English
alphabetical basis, which may not accommodate those who do not necessary have an English name or want to express
their names in a language other than that of English. Some culture's names do not even fit in the pattern of first
and last names. However, on a better note, its generated date times are fairly standard as the general structure of
months and years are generally agreed upon. The datetime is hard
formatted into month/day/year, which means it's most advisable when inquiring
information from the user to ask the user to select a date rather than typing one in, as that may confuse the
database. Its emails have a large variety of domains to them, from those that you would expect such as
"@gmail.com" and "@yahoo.com" to many other domains such as a very Chinese specific email address "@weibo.com" or
even some obscure ones like "@e-recht24.de", and it's certainly explored a large variety of emails. Its gender
option seems to offer a discrete set of names, specifically "Male", "Female", "Polygender", "Agender", "Genderfluid",
"Bigender", "Genderqueer", and "Non-binary", without any other genders included. While this is fairly comprehensive
range wise, it also seems to assume that there aren't any other options outside the selected few.
It would be also advisable, when collecting real userdata, to add an optional field where the user
can enter whichever specifications on their gender they wish to choose as opposed to broadly categorizing them
as such. Finally, for Street Addresses, the format of the street address is in "[street number] [name] [suffix]",
which are fairly standard in America. However, the arrangement and structure of addresses may be different in
other countries. Some countries may have their street names first and then the specific number.
In addition, other countries may assign a completely different language to the name of their roads. Some streets might
not even have numbers but just names to their destinations.

2. When you made decisions about how you modelled your dataset, you made predictions about what
future data you would be encountering. How did you make these decisions? Can you think of any edge cases
that might break your model?

In the construction of my dataset and MockPerson, I made a few assumptions about the future data I would be
encountering. First, I assumed that given an entry, the first and last name of the entry (or for that matter
all entries in the CSV) cannot contain commas because my parser's designed to split by "," in the entry. Even if
I want to split the data with the exception of commas in double quotes. The data generated by Mockaroo
did not put the names in quotations. But there are certainly names with commas in it such as "King George, the III".
However, I believe one way to partially address this issue is the fact that the entire name would be split
between the first and last name, so the title of a person's name could be instead put in the last name field.
Other than that, I endeavored to make the least assumptions about the names I would be encountering. I remember
reading an article, back in CS-0190, about "Falsehoods Programmers Believe About Names – With Examples", that showed
a variety of assumptions that Programmers may have on names such as names do not have numbers, or that they are
not in All Caps, etc. However, this is naturally a false assumption because everyone deserves the right to choose
whatever name they should be called; therefore, naturally, any assumptions about these names would be broken.
Even empty names exist too, and cases where people with no names are certainly possible too. There are tribes who'd
addressed each member in relative terms rather than assigning names to them, and someone could choose to go without
having a name at all. Therefore, the names parameters accepts whatever strings passed in. This is very much the
same with Genders too, so anything the user wishes to put in would be accepted. Empty cases are handled, when
being outputed, as "[Undeclared/Empty]".

As for birth dates, the fields are assumed to be in the format mm/dd/yyyy, and other formats of dates would be
rejected instead. This decision is largely due to how Mockaroo decided to structure their dates, but
realistically matters like entering dates should be best handled by selecting a date on a calendar rather than
letting the user manually input one in.

As for emails and street addresses, both of them can also be empty as the person may not have an email address or
a stable place of residence. The format of the emails are assumed to be in the form [username]@[domain], usernames
and domains can only contain dashes, underscores, slashes, periods, and alphanumerics, while domains must have at
least one period in them. There are emails that may break this, such as those having local groups, but for
general users with personal emails rather than domain specific subemails, the validation should suffice.
However, maybe the best way to validate emails isn't necessarily to pass them through any string validation checks
but to rather than the user an email for confirmation/activation. Since the user has to be respond to the
confirmation/activation, their response is an indication of whether or not the email address is valid. As for the
street address, the assumption is that they originate from US street addresses and thus have street numbers in the
beginning. Since Mockaroo's street addresses did not generate the county or state or postal code associated with
them, the validation is only to the street itself. Streets from other countries may break this; therefore, it
may be more advisable to separate the form into fields such as "Street Number" and "Street Name", etc. to be able
to organize the data better.

3. In this assignment we ask you to build an extensible REPL. How have you made your REPL extensible
(beyond accessing multiple commands)? Let’s say you wanted to reuse your REPL code.
What changes need to be made (if any) to your REPL? Consider the inversion-of-control reading
and Lecture 2.In this assignment we ask you to build an extensible REPL.

Following the inversion of control and the strategic pattern discussed in Lecture 2, rather than putting the
entire REPL in the main method, and chaining different command objects directly to the Main Method, the main
method instead only created an REPLRunner object with a single method run. This is done so that in the event
that the Main Method decides to switch to another runner, the switch would be as simple as removing the two lines
of REPLRunner and creating a new object.

As for executing the commands from REPL, rather than connecting the logic of the comands directly to the
REPLRunner, I instead made all commands extend from an Interface called "Command" with only two default methods
- execute and matchArgsToMethod. "execute" is the actual execution of the command while "matchArgsToMethod" is
a validation of the arguments being passed to the command to determine if the command should be executed and
which form of the command to choose. A Hashmap is set up to key the first string of the split (after being split
by space) to whatever command object the input matches too. In the loop for REPL, no specific methods are called,
rather it checks if the Hashmap has the key given, and, if so, executes the command (the execution checks if
the argumentss are valid). It is done to avoid cases where a series of nested if statements dominate the
REPL loop instead.

Therefore, when I would reuse my REPL code, all I need is to copy the exact same run method to the new object,
the command interface, the Hashmap, and resolving import dependencies. Adding a new command would as simple as
adding a new entry in the command with its name as key and the object extending from command as the value.
